# О ПРОЕКТЕ:

Используем:
- ePytorch, Transformers, TRL, и PEFT (если будут проблемы с ресурсамы, попробуем unsloth)

# ЗАДАЧИ:

## Подготовка
- [x] Настроить репозиторий на GitHub
- [x] Создать ноутбук Kaggle, загрузить датасет, синхронизировать с GitHub
- [ ] Бенчмарки для моделей:
	- [ ] qwen/qwen3-8b:free
	- [ ] qwen/qwen3-1.7b:free
	- [ ] deepseek/deepseek-r1-0528-qwen3-8b:free
	- [ ] deepseek/deepseek-r1-0528:free
- Прочесть:
	- [ ] [DeepSeek-Prover-V2](https://arxiv.org/pdf/2504.21801)
	- [ ] [DeepSeekMath](https://arxiv.org/pdf/2402.03300)
	- [ ] [Глубокое обучение с подкреплением в пространстве естественно-языковых действий](https://arxiv.org/pdf/1511.04636)

## Сбор данных
- [ ] Проверить и очистить датасет при необходимости
- [ ] Перевести существующие задачи (из датасета) на все включённые языки
- [ ] Изучить организацию датасетов для RL (особенно математических)
- [ ] Найти и систематизировать внешние датасеты для возможного использования

## Обучение
- Изучить методику применения RL для математики с GRPO
- Создать первый простой ноутбук с GRPO
- Разделить данные:
	- Полный набор (все языки)
	- Отдельные наборы для каждого языка
	- *Возможно разделение по сложности задач (на основе результатов базовых моделей)*
- Обучение небольшой модели:
	***Обязательно провести оценку базовых показателей до тонкой настройки***
	- [ ] Тонкая настройка малой модели (qwen 1.7b или 0.6b) с использованием RL-ноутбука
	- [ ] Оценка и сравнение с базовыми показателями
	- [ ] Корректировка
	- [ ] ***Повтор***
	При достижении удовлетворительных результатов:
- Обучение крупной модели по проверенной методике:
	***Обязательно провести оценку базовых показателей до тонкой настройки***
	- Обучить модель **DeepSeek-R1-0528-Qwen3-8B**
	- Оценка
	- Корректировка
	- ***Повтор***
- Создать финальный Jupyter-ноутбук и представить результаты
